{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5153b6b2-f75e-4086-ae02-935dd7f9a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from syndata import get_exo_locations\n",
    "import pandas as pd\n",
    "from get_syndata import *\n",
    "from models import Exocoder,vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4efe82-b682-4267-b9c8-5f01fc8959b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,star,exo,transform=True,labelled=True):\n",
    "            \n",
    "        self.star      = star\n",
    "        self.exo       = exo\n",
    "        self.transform = transform \n",
    "        self.labelled  = labelled\n",
    "        \n",
    "        if labelled:\n",
    "        \n",
    "            self.arr      = np.concatenate((exo[0],star[0]))\n",
    "            self.label    = torch.vstack((exo[1],star[1]))\n",
    "        \n",
    "            self.data = [self.arr,self.label]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.data      = np.concatenate((exo,star))\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.arr) if self.labelled  else len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "    \n",
    "        if self.labelled:\n",
    "            sample = self.data[0][idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                sample = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.CenterCrop(160),\n",
    "                       ])(sample)\n",
    "                \n",
    "            label  = self.data[1][idx]\n",
    "            return [sample,label]\n",
    "        \n",
    "        else:\n",
    "            sample = self.data[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                sample = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.CenterCrop(160),\n",
    "                       ])(sample)\n",
    "            \n",
    "            return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fddcc3-4d8a-4dc5-a891-278d4624b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exo data: (12300, 320, 320)\n",
      "Star data: (8064, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "train_star, train_exo, test_star, test_exo = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9916e1e-521c-4430-9300-a752a7f87a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SyntheticDataset(star=train_star,exo=train_exo,labelled=False)\n",
    "test_dataset = SyntheticDataset(star=test_star,exo=test_exo,labelled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ad591e-9b14-4f84-af7d-1a6d5cc0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=512,shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9eb3b0-3f5b-467b-b53e-6366b3d8cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,train_samples = next(enumerate(train_dataloader))\n",
    "_,test_sample = next(enumerate(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb7ca41-2124-41a6-983d-31914a1cdbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = torch.concat((train_samples[0],train_samples[0]))\n",
    "test_stack  = torch.concat((test_sample[0],test_sample[0]))\n",
    "for i in range(2,25):\n",
    "    \n",
    "    train_stack = torch.concat((train_stack,train_samples[i]),axis=0)\n",
    "    test_stack = torch.concat((test_stack,test_sample[i]),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e7c71f-4c24-41a3-9aa3-15eb5dc2a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_data(train_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a399df6-cc03-442f-9227-a7e8c1a51f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conv_dims(input_size,paddings:list,kernels:list,strides:list,maxpool:list):\n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(input_size)\n",
    "    for i in range(len(paddings)):\n",
    "        \n",
    "        output_size = (input_size + (2*paddings[i]) - (kernels[i] - 1) - 1)/strides[i] + 1\n",
    "        if maxpool[i] != 0:\n",
    "            print('0')\n",
    "            output_size = (output_size  + (2*paddings[i]) - (maxpool[i]-1)-1)/2 +1\n",
    "        \n",
    "        outputs.append(int(output_size))\n",
    "        input_size = output_size\n",
    "        \n",
    "    print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef77853-d0bc-45fe-bcb9-4468425e4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_convtrans_dim(input_size,paddings:list,kernels:list,strides:list):\n",
    "    outputs = []\n",
    "    outputs.append(input_size)\n",
    "    for i in range(len(paddings)):\n",
    "        \n",
    "        output_size = (input_size - 1) * strides[i]  -  2 * paddings[i] + kernels[i] - 1 + 1\n",
    "        outputs.append(int(output_size))\n",
    "        input_size = output_size\n",
    "        \n",
    "    print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd29ea1-c6d1-4707-9d9d-cdee9daceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_forward = [3,3,3,3,3,3,3,3,3]\n",
    "paddings_forward= [0,0,0,0,0,0,0,0,0]\n",
    "strides_forward = [1,1,1,2,1,1,1,2,1]\n",
    "maxpool = [0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597cbdcc-82c5-4169-b50f-6cfa3b712cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_backward = [3,3,3,3,3,3,2]\n",
    "paddings_backward= [0,0,0,0,0,0,0]\n",
    "strides_backward = [1,1,1,2,1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "571cbc4e-38a6-4727-989c-b0a36798d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160, 158, 156, 154, 76, 74, 72, 70, 34, 32]\n"
     ]
    }
   ],
   "source": [
    "convdim_outputs = calculate_conv_dims(160,paddings_forward,kernels_forward,strides_forward,maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f38468-e15d-473a-804f-3936b0d3b803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 34, 36, 38, 77, 79, 159, 160]\n"
     ]
    }
   ],
   "source": [
    "convtrans_outputs = calculate_convtrans_dim(32,paddings_backward,kernels_backward,strides_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba4c5ba9-5af8-4947-8ac2-342118793215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exocoder(nn.Module):\n",
    "\n",
    "    def __init__(self,convdim_outputs_e:list,kernels_e:list,strides_e:list,convdim_outputs_d:list,kernels_d:list,strides_d:list,latent_dim:int):\n",
    "\n",
    "        super(Exocoder,self).__init__()\n",
    "\n",
    "        self.convdim           = convdim_outputs_e\n",
    "        self.kernels           = kernels_e\n",
    "        self.strides           = strides_e\n",
    "        self.convtranspose     = convdim_outputs_d\n",
    "        self.kernelsd          = kernels_d\n",
    "        self.stridesd          = strides_d\n",
    "        self.latent_dim        = latent_dim\n",
    "\n",
    "        self.C                 = 8\n",
    "\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(in_channels=1,out_channels=self.C,stride=self.strides[0],kernel_size=self.kernels[0]), #1\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C,stride=self.strides[1],kernel_size=self.kernels[1]), #2\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C,stride=self.strides[2],kernel_size=self.kernels[2]), #3\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C*2,stride=self.strides[3],kernel_size=self.kernels[3]), #4 \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=self.strides[4],kernel_size=self.kernels[4]), #5\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=self.strides[5],kernel_size=self.kernels[5]), #6\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=self.strides[6],kernel_size=self.kernels[6]), #7\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=self.strides[7],kernel_size=self.kernels[7]), #8\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=self.strides[8],kernel_size=self.kernels[8]), #9\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear((self.C*2)*self.convdim[-1]**2,self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.mean   = nn.Linear(self.latent_dim,(self.C*2)*self.convdim[-1]**2)\n",
    "        self.logvar = nn.Linear(self.latent_dim,(self.C*2)*self.convdim[-1]**2)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "            nn.Unflatten(1,(self.C*2,self.convdim[-1],self.convdim[-1])),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, kernel_size=self.kernelsd[0], stride=self.stridesd[0]), #1\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, kernel_size=self.kernelsd[1], stride=self.stridesd[1]), #2\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, kernel_size=self.kernelsd[2], stride=self.stridesd[2]), #3\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, kernel_size=self.kernelsd[3], stride=self.stridesd[3]), #4\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, kernel_size=self.kernelsd[4], stride=self.stridesd[4]), #5\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C, kernel_size=self.kernelsd[5], stride=self.stridesd[5]), #6\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=self.C, out_channels=1, kernel_size=self.kernelsd[6], stride=self.stridesd[6]), #7\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def reparametrize(self,mean,logvar):\n",
    "\n",
    "        eps = torch.randn(mean.size(0),mean.size(1)).to(device)\n",
    "        z = mean + torch.exp(logvar/2) * eps\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        mean = self.mean(x)\n",
    "        logv = self.logvar(x)\n",
    "\n",
    "        z = self.reparametrize(mean,logv)\n",
    "\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        return x_recon, z, mean, logv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0066938-6141-4582-9cc8-60bdddfc352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Exocoder(convdim_outputs_e=convdim_outputs,\n",
    "                 kernels_e=kernels_forward,\n",
    "                 strides_e=strides_forward,\n",
    "                 convdim_outputs_d=convtrans_outputs,\n",
    "                 kernels_d=kernels_backward,\n",
    "                 strides_d=strides_backward,\n",
    "                 latent_dim=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2730f2ea-6ab0-4362-90e7-a00d9afd1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "model = model.to(device)\n",
    "#model = model.to(f'cuda:{model.device_ids[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e717f05-559b-4667-9579-7c6b090dd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,optimizer,device,loss_fn,EPOCH=30):\n",
    "    \n",
    "    with tqdm(total = len(train_dataloader) * EPOCH) as tt:\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            \n",
    "            total_loss, batch_count = 0, 0\n",
    "            \n",
    "            for idx, batch in enumerate(train_dataloader):\n",
    "                \n",
    "                batch = batch.float().to(device)\n",
    "                \n",
    "                x_recon, z, mean, logv = model(batch)\n",
    "                \n",
    "                loss = loss_fn(x_recon,batch,mean,logv)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                tt.update()\n",
    "                \n",
    "            total_loss = total_loss / batch_count\n",
    "            print(f'{total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2802753-17bf-4901-bfff-1f79a22f6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_recon,x,mean,logv):\n",
    "\n",
    "    recons = F.mse_loss(x_recon, x, reduction='sum')\n",
    "    kl = -0.5 * torch.sum(1 + logv - mean.pow(2) - logv.exp())\n",
    "    kl /= 512 * 160 * 160\n",
    "    \n",
    "    return recons + kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866fcfa2-7537-4214-b452-c7d7c0474c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5d93ad6-3cf8-4fcf-b691-c4bfed92206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                        | 36/720 [00:18<05:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548280817891.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 72/720 [00:33<04:12,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521404131100.44446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▎                                                               | 108/720 [00:50<04:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376550740423.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████                                                            | 144/720 [01:04<04:30,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300950278144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████▊                                                        | 180/720 [01:22<04:09,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274222328945.77777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▌                                                    | 216/720 [01:37<03:50,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253728578218.66666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▎                                                | 252/720 [01:53<02:29,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240802850588.44446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████                                             | 288/720 [02:09<03:12,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236366879857.77777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████▊                                         | 324/720 [02:24<02:20,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233384838485.33334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▌                                     | 360/720 [02:41<02:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231246154865.77777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▎                                 | 396/720 [02:56<02:17,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229068593379.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████                              | 432/720 [03:13<02:11,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227205925091.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████▊                          | 468/720 [03:28<01:53,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225486291399.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▌                      | 504/720 [03:45<01:13,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223836851768.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▎                  | 540/720 [04:00<01:20,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222467168483.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████               | 576/720 [04:15<00:38,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221145360611.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▊           | 612/720 [04:31<00:46,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219934900679.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▌       | 648/720 [04:45<00:20,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218720233699.55554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████▎   | 684/720 [05:01<00:16,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217575862272.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 720/720 [05:16<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216318269212.44446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model=model,train_dataloader=train_dataloader,optimizer=optimizer,loss_fn=vae_loss,device=device,EPOCH=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89a4e7c3-aed1-44ec-876a-48f30a7682be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn((100,16*32*32)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6743dc8-0de7-4f22-8df0-ed2cbba7a5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 160, 160])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb8f35-8cc5-4845-be32-7da9bc6ad371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
