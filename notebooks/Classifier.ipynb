{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a9ace-95fb-439f-a2bb-b10c429b3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from syndata import get_exo_locations\n",
    "import pandas as pd\n",
    "from get_syndata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad940c-6bac-4c51-b6b9-711a3d7b1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,star:list,exo:list,transform=True,labelled=True):\n",
    "            \n",
    "        self.star      = star\n",
    "        self.exo       = exo\n",
    "        self.transform = transform\n",
    "        self.labelled  = labelled\n",
    "        \n",
    "        if labelled:\n",
    "        \n",
    "            self.arr      = np.concatenate((exo[0],star[0]))\n",
    "            self.label    = torch.vstack((exo[1],star[1]))\n",
    "        \n",
    "            self.data = [self.arr,self.label]\n",
    "            \n",
    "        else:\n",
    "            self.data      = np.concatenate((exo[0],star[0]))\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.arr)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        sample = self.data[0][idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.CenterCrop(160),\n",
    "                   ])(sample)\n",
    "        \n",
    "        if self.labelled:\n",
    "            \n",
    "            label  = self.data[1][idx]\n",
    "            return [sample,label]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7e931-92ed-46a2-9e45-85afbb4b1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_star, train_exo, test_star, test_exo = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77422d52-345d-42dc-bd9e-fd256046ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_star_labelled, train_exo_labelled, test_star_labelled, test_exo_labelled = get_labelled_data(train_star, train_exo, test_star, test_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591ff45-7cfb-4ea5-a188-175a4289e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SyntheticDataset(star=train_star_labelled,exo=train_exo_labelled,labelled=True)\n",
    "test_dataset = SyntheticDataset(star=test_star_labelled,exo=test_exo_labelled,labelled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ef899-70bc-446b-8823-e6f6f7f5f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=512,shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c172907-27ca-4172-ae09-739aeb2510aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,train_samples = next(enumerate(train_dataloader))\n",
    "_,test_sample = next(enumerate(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d92b19-c55f-41a7-9308-6b17d25ad56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25e3c8-6b1f-4f6e-87f9-cdfebc02466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_locs = [] \n",
    "#for x,y in exo_locs:\n",
    "#    x_new, y_new = x-80,y-80\n",
    "#    new_locs.append((x_new,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2ae5c-2515-4ae8-b7d6-9b79b4e919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = torch.concat((train_samples[0][0],train_samples[0][1]))\n",
    "test_stack  = torch.concat((test_sample[0][0],test_sample[0][1]))\n",
    "for i in range(2,25):\n",
    "    \n",
    "    train_stack = torch.concat((train_stack,train_samples[0][i]),axis=0)\n",
    "    test_stack = torch.concat((test_stack,test_sample[0][i]),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fd740-d5f3-4be9-b14a-5658539c9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syndata import get_exo_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e32e2-dcda-474e-9008-2fafa5bbeae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_data(train_stack,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11f30c-925b-48f0-903f-e15e0c457107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_data(test_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d641b-3c6c-4fcd-8310-f50dcc62a72a",
   "metadata": {},
   "source": [
    "# Conv Calculater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2ad52-22aa-4fcd-8f78-f1fbd326f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conv_dims(input_size,paddings:list,kernels:list,strides:list,maxpool:list):\n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(input_size)\n",
    "    for i in range(len(paddings)):\n",
    "        \n",
    "        output_size = (input_size + (2*paddings[i]) - (kernels[i] - 1) - 1)/strides[i] + 1\n",
    "        if maxpool[i] != 0:\n",
    "            print('0')\n",
    "            output_size = (output_size  + (2*paddings[i]) - (maxpool[i]-1)-1)/2 +1\n",
    "        \n",
    "        outputs.append(int(output_size))\n",
    "        input_size = output_size\n",
    "        \n",
    "    print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed006dc-bb70-4211-a13a-dccfdfe7874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_forward = [3,3,3,3,3,3,3,3,3]\n",
    "paddings_forward= [0,0,0,0,0,0,0,0,0]\n",
    "strides_forward = [1,1,1,2,1,1,1,2,1]\n",
    "maxpool = [0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bbded-74e5-400f-a141-3491b3bf5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convdim_outputs = calculate_conv_dims(160,paddings_forward,kernels_forward,strides_forward,maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40b783-ee7c-44be-ab6e-1ed1bc697767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_convtrans_dim(input_size,paddings:list,kernels:list,strides:list):\n",
    "    outputs = []\n",
    "    outputs.append(input_size)\n",
    "    for i in range(len(paddings)):\n",
    "        \n",
    "        output_size = (input_size - 1) * strides[i]  -  2 * paddings[i] + kernels[i] - 1 + 1\n",
    "        outputs.append(int(output_size))\n",
    "        input_size = output_size\n",
    "        \n",
    "    print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565a4e6-a820-4152-9d92-f0534c6e7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_backward = [3,3,3,3,3,3,2]\n",
    "paddings_backward= [0,0,0,0,0,0,0]\n",
    "strides_backward = [1,1,1,2,1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38413e93-de32-42f4-bcfd-49242562c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convtrans_outputs = calculate_convtrans_dim(32,paddings_backward,kernels_backward,strides_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d3b70-5cb8-4c7c-aa6d-cd7c36817796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027a895-0cb6-4b1f-9650-90dc6ae38cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exonet(nn.Module):\n",
    "    \n",
    "    def __init__(self,convdim_outputs:list,kernels:list,strides:list):\n",
    "        \n",
    "        super(Exonet,self).__init__()\n",
    "        \n",
    "        self.convdim = convdim_outputs\n",
    "        self.kernels = kernels\n",
    "        self.strides = strides\n",
    "        self.C       = 8 \n",
    "        \n",
    "        self.exonet  = nn.Sequential(\n",
    "                        \n",
    "            nn.Conv2d(in_channels=1,out_channels=self.C,stride=strides[0],kernel_size=kernels[0]), #1\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C,stride=strides[1],kernel_size=kernels[1]), #2\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C,stride=strides[2],kernel_size=kernels[2]), #3\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C,out_channels=self.C*2,stride=strides[3],kernel_size=kernels[3]), #4 \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=strides[4],kernel_size=kernels[4]), #5\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=strides[5],kernel_size=kernels[5]), #6\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=strides[6],kernel_size=kernels[6]), #7\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=strides[7],kernel_size=kernels[7]), #8\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2,out_channels=self.C*2,stride=strides[8],kernel_size=kernels[8]), #9\n",
    "            nn.ReLU(),\n",
    "        \n",
    "        ) \n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "        \n",
    "                nn.Linear((self.C*2)*convdim_outputs[-1]**2,4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096,1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024,2),\n",
    "                nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.exonet(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d5e24-4f85-4da9-8e95-378cdee753ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a6bd1-6c21-46fd-bd19-59885ad579e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "model = Exonet(convdim_outputs,kernels_forward,strides_forward)\n",
    "batch_size = 512\n",
    "# device='meta' -> no memory is consumed for visualization\n",
    "model_graph = draw_graph(model, input_size=(batch_size,1 , 160, 160), device='meta')\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e30ad-ce85-4be4-994c-d5c481108441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0, 3\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0.\n",
    "#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
    "#model = Exonet(convdim_outputs,kernels_forward,strides_forward)\n",
    "model  = torch.load('model1.pt')\n",
    "#model  = nn.DataParallel(model,device_ids = [0, 1, 2, 3])\n",
    "#model = model.to(device)\n",
    "#model = model.to(f'cuda:{model.device_ids[0]}')\n",
    "model = nn.DataParallel(model)\n",
    "#torch.onnx.export(model, dummy_input, 'r.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ea456-9cc6-4ded-9d57-d631fabf42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(512, 1, 160, 160, device=\"cuda\")\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4032d-a490-4437-a7ca-2b6317f53f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efabc8-947a-4b3c-9013-cda815bbcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(512, 1, 160, 160, device=\"cuda\")\n",
    "# Providing input and output names sets the display names for values\n",
    "# within the model's graph. Setting these does not change the semantics\n",
    "# of the graph; it is only for readability.\n",
    "#\n",
    "# The inputs to the network consist of the flat list of inputs (i.e.\n",
    "# the values you would pass to the forward() method) followed by the\n",
    "# flat list of parameters. You can partially specify names, i.e. provide\n",
    "# a list here shorter than the number of inputs to the model, and we will\n",
    "# only set that subset of names, starting from the beginning.\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1703bb7-62e9-4b65-a517-845ef471cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ee963-4b05-442b-a736-12a107912db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,optimizer,device,loss_fn,EPOCH=30):\n",
    "    \n",
    "    with tqdm(total = len(dataloader) * EPOCH) as tt:\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            \n",
    "            total_loss, batch_count = 0, 0\n",
    "            \n",
    "            for idx,(batch,label) in enumerate(dataloader):\n",
    "                \n",
    "                batch  = batch.float().to(f'cuda:{model.device_ids[0]}')\n",
    "                label  = label.float().to(f'cuda:{model.device_ids[0]}')\n",
    "                \n",
    "                output = model(batch)\n",
    "                \n",
    "                loss = loss_fn(label,output)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                tt.update()\n",
    "                \n",
    "            total_loss = total_loss / batch_count\n",
    "            print(f'{total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4964eef-f63e-4963-a168-3f29dcc4af1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train(model=model,dataloader=train_dataloader,optimizer=optimizer,loss_fn=loss_fn,device=device,EPOCH=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28076ec3-38b6-4a8e-867b-18996c38a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = enumerate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dc4e1-2bfc-4a24-b8cd-b557a5f90670",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,test_sample = next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b8648-4f1f-4b12-ae35-84376b46339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(test_sample[0].float().to(f'cuda:{model.device_ids[0]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82952f3-8291-4a34-ac06-05985a14dd4d",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de4447-74d9-4fe1-b923-69326ac7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(test_loader,model):\n",
    "    logs = {}\n",
    "    false_ = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        arr = torch.randn((1,160,160)).to(f'cuda:{model.device_ids[0]}')\n",
    "        \n",
    "        for idx, (images,target) in enumerate(test_loader):\n",
    "            \n",
    "            images = images.float().to(f'cuda:{model.device_ids[0]}')\n",
    "            target = target.float().to(f'cuda:{model.device_ids[0]}')\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predicted = torch.floor(outputs)\n",
    "            \n",
    "            where = torch.argwhere(torch.abs(predicted - target))\n",
    "            \n",
    "            for i in range(len(where)):\n",
    "                \n",
    "                arr = torch.vstack((arr,images[where[i][0]]))\n",
    "            \n",
    "            incorrect += torch.sum(torch.abs(predicted-target))\n",
    "            \n",
    "            correct += torch.abs(len(target) - incorrect)\n",
    "            \n",
    "            total += len(target) \n",
    "            \n",
    "        print('Incorrect:',int(incorrect))\n",
    "        print('Correct:',int(correct))\n",
    "        print('Total:',total)\n",
    "        print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
    "        #logs['accuracy'] = accuracy\n",
    "        \n",
    "        \n",
    "    return arr[1:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15837d4-661a-466f-aff0-c67cd50ffef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_classes = test_(test_dataloader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dee637-6024-4078-8fbe-1b070a300123",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for idx, (images,labels) in enumerate(test_dataloader):\n",
    "    \n",
    "    images = images.float().to(f'cuda:{model.device_ids[0]}')\n",
    "    labels = labels.float().to(f'cuda:{model.device_ids[0]}')\n",
    "    \n",
    "    y_true.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    outputs=model(images)\n",
    "\n",
    "    predicted = torch.floor(outputs)\n",
    "    y_pred.extend(predicted.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15929798-4c9b-4563-93c9-01fea371c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = []\n",
    "predicted_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e6a79-2e89-4022-bdfe-72825e219158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_true)):\n",
    "    \n",
    "    if y_true[i][0] == 1.:\n",
    "        true_classes.append('exo')\n",
    "        \n",
    "    if y_true[i][0] == 0.:\n",
    "        true_classes.append('star')\n",
    "        \n",
    "    if y_pred[i][0] == 1.:\n",
    "        predicted_classes.append('exo')\n",
    "        \n",
    "    if y_pred[i][0] == 0.:\n",
    "        predicted_classes.append('star')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee17bd6-7024-40d7-8830-8f05e8dd21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a697ba4-5da1-4f32-a45f-eb2be117384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(true_classes, predicted_classes, labels=[\"exo\", \"star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfa316-b326-4284-a2a0-afaf21022a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('exo','star')\n",
    "dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e51c55-4bb3-499f-9b95-75ba4668f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3ed3-8445-4bc2-b1e9-64ec7f9a6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    " \n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
    " \n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    " \n",
    "plt.ylabel(\"True Class\"), \n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30ef66-f3ec-4e63-89dc-67ac11ebe897",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "recall = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[1][0])\n",
    "f1 = (2*(precision)*recall)/precision+recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa16f2-9171-472f-a345-cc3252d0af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1 score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088e0d1-8631-4d12-8928-11cd612c9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(false_classes.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d87099-7756-45e9-9e4e-6fa2be328637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2ca2-0558-4702-9aaa-12de37d7505d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399270c9-5327-4b2b-9cac-543c5d41fb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005456c9-69cc-4639-9a54-a266cc6befc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
