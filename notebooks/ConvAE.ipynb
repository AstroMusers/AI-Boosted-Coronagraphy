{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09496bc1-2072-4544-89b9-5d706bdcfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from glob import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import umap\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7c15bc-36a2-4850-a538-b8b8385e8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'/home/sarperyn/sarperyurtseven/ProjectFiles/dataset/NIRCAM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915aba3-5805-4007-bd42-161250faec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files = glob(os.path.join(directory,'**/*.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9159d6a-d89c-42b9-916c-4560e58e3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c146879-789c-48f5-b623-df8bc64f1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066380-1eeb-4e8b-a888-f49ec279d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyH5Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,h5_paths):\n",
    "        \n",
    "        self.h5_paths  = h5_paths\n",
    "        self._archives = [h5py.File(h5_path,\"r\") for h5_path in self.h5_paths]\n",
    "        self.keys      = {}\n",
    "        self.d = {}\n",
    "        \n",
    "        idx  = 0\n",
    "        idx2 = 0\n",
    "        \n",
    "        \n",
    "        for a, archive in enumerate(self.archives):\n",
    "            \n",
    "            for i in range(len(archive)):\n",
    "                \n",
    "                key = list(archive.keys())[i]  \n",
    "                self.keys[idx] = (a, key)\n",
    "                idx += 1\n",
    "                \n",
    "                for j in range(archive[key].shape[0]):\n",
    "                    \n",
    "                    self.d[idx2] = archive[key][j]\n",
    "                    idx2 +=1\n",
    "                    \n",
    "        self._archive=None\n",
    "    @property\n",
    "    def archives(self):\n",
    "        if self._archives is None: \n",
    "            self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.h5_paths]\n",
    "        return self._archives\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.d)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        data = self.d[index].astype(np.float32)\n",
    "        data = torch.from_numpy(data)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4401d-5c57-4a79-a8fd-46e704fe5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(MyH5Dataset(h5_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8bd3-5adf-49c1-9e05-9469ee12f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "doenum = enumerate(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847771fc-ab4b-4d70-9534-7a334c946c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,data = next(doenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4799fb5-35b8-41e6-a991-2fa89bf6380a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac91272-fa33-4458-aa7d-b0de5524267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105fcf4a-bc25-4585-9b64-137002e577a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b454f3c-15c1-4ca9-a994-b1d60e11cfbf",
   "metadata": {},
   "source": [
    "# ConvVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b89e7-1f39-4d38-b7a8-21baefa9568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self,latent_dim=200):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=1,out_channels=8,stride=1,kernel_size=5), #320x320x1 --> 316x316x8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=8,out_channels=16,stride=1,kernel_size=3), #316x316x8 --> 314x314x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=16,out_channels=16,stride=2,kernel_size=4), #314x314x16 --> 156x156x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=16,out_channels=20,stride=1,kernel_size=3), #156x156x16 --> 154x154x20\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.mean    = nn.Linear(474320,latent_dim)\n",
    "        self.log_var = nn.Linear(474320,latent_dim)\n",
    "        self.linear  = nn.Linear(latent_dim,474320) \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=20,out_channels=16,stride=1,kernel_size=3), # 154x154x20 --> 155x155x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=16,out_channels=16,stride=2,kernel_size=4), # 155x155x16 --> 312x312x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=16,out_channels=8,stride=1,kernel_size=4), # 312x312x16 --> 314x314x8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8,out_channels=1,stride=1,kernel_size=7), # 314x314x8 --> 320x320x3\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self,z_mean,z_log_var):\n",
    "        \n",
    "        eps = torch.randn(z_mean.size(0),z_mean.size(1))\n",
    "        z = z_mean + torch.exp(z_log_var/2) * eps\n",
    "        \n",
    "        return z\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(1,-1)\n",
    "        z_mean, z_log_var = self.mean(x), self.log_var(x)\n",
    "        \n",
    "        \n",
    "        encoded = self.reparameterize(self.mean(x), self.log_var(x))\n",
    "        \n",
    "        x = self.linear(encoded)\n",
    "        \n",
    "        x = x.view(1,20,154,154)\n",
    "        \n",
    "        decoded = self.decoder(x)\n",
    "        \n",
    "        \n",
    "        return encoded, z_mean, z_log_var, decoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01578c-931a-4916-b7ea-e8cee333cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(decoded,x,z_mean,z_log_var):\n",
    "    \n",
    "    x = x.view(x.size(0),-1)\n",
    "    \n",
    "    recons = F.mse_loss(decoded, x, reduction='sum')\n",
    "    kl = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "    \n",
    "    return recons + kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03595b66-0ef3-4449-bb42-a8be51522cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = ConvVAE()\n",
    "optimizer = torch.optim.Adam(vae_model.parameters(), lr=3e-4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e6c46-c052-43f1-9815-d6ae8bd32d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,loss_fn,device,EPOCH):\n",
    "    \n",
    "    with tqdm(total=len(train_loader)*EPOCH*555) as tt:\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            \n",
    "            total_loss, batch_count = 0, 0\n",
    "            \n",
    "            for idx, batch in enumerate(train_loader):\n",
    "                \n",
    "                batch = batch['data']\n",
    "                batch = batch.view(batch.size(1),batch.size(0),batch.size(2),batch.size(3))\n",
    "                \n",
    "                for psf in batch:\n",
    "                    \n",
    "                    #print(batch.shape)\n",
    "                    encoded, z_mean, z_log_var, reconstruction = model(psf)\n",
    "\n",
    "                    loss = loss_fn(reconstruction,batch,z_mean,z_log_var)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    batch_count +=1\n",
    "                    tt.update()\n",
    "\n",
    "                \n",
    "            total_loss = total_loss / batch_count\n",
    "            print(f'{total_loss}')\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cf7f9-bad5-44f1-a382-6a9ecaa9c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=vae_model,train_loader=loader,optimizer=optimizer,loss_fn=vae_loss,device=device,EPOCH=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeeedad-e347-4938-9823-e8b098e8f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_resultsVAE(model,data_loader,data):\n",
    "    dataiter = iter(data_loader)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    images, labels = dataiter.next()\n",
    "    \n",
    "    images_flatten = images.view(images.size(0), -1)\n",
    "    _,_,_,output = model(images_flatten)\n",
    "    \n",
    "    images = images.numpy()\n",
    "    output = output.view(32, 1, 28, 28)\n",
    "\n",
    "\n",
    "    output = output.cpu().detach().numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=15, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "    for images, row in zip([images, output], axes):\n",
    "        for img, ax in zip(images, row):\n",
    "            \n",
    "            ax.imshow((np.transpose(img,(1, 2, 0))*255).astype(np.uint8),cmap='gray')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f70f67-480f-4dfb-b566-98c8192e4e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf8972-97da-4204-922c-83208b4f4122",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_resultsVAE(model=vae_model,data_loader=loader,data='fmnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
