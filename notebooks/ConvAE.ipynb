{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09496bc1-2072-4544-89b9-5d706bdcfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from glob import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import umap\n",
    "import umap.plot\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c9a86-0382-4a85-aa0f-ec213123e196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c15bc-36a2-4850-a538-b8b8385e8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'/home/sarperyn/sarperyurtseven/ProjectFiles/dataset/NIRCAM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915aba3-5805-4007-bd42-161250faec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files = glob(os.path.join(directory,'**/*160.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9159d6a-d89c-42b9-916c-4560e58e3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0188ae2-3528-45f6-bf2c-690f1dd40137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1441 = [h5py.File(h5_path,\"r+\") for h5_path in h5_files][0]\n",
    "#data1386 = [h5py.File(h5_path,\"r+\") for h5_path in h5_files][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91817451-cbbd-42e4-a237-783de6c45ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys = [x for x in [h5py.File(h5_path,\"r+\") for h5_path in h5_files][0].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e8657-9849-4bb2-8ffb-800efd986cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1441[keys[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd960e-f4d9-4cbd-b764-b3611b63824e",
   "metadata": {},
   "source": [
    "* rotated_shifted_135\n",
    "* rotated_shifted_270\n",
    "* shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c146879-789c-48f5-b623-df8bc64f1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066380-1eeb-4e8b-a888-f49ec279d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,h5_paths):\n",
    "        \n",
    "        self.h5_paths  = h5_paths\n",
    "        self._archives = [h5py.File(h5_path,\"r+\") for h5_path in self.h5_paths]\n",
    "        self.keys      = {}\n",
    "        self.d = {}\n",
    "        \n",
    "        idx  = 0\n",
    "        idx2 = 0\n",
    "        \n",
    "        \n",
    "        for a, archive in enumerate(self.archives):\n",
    "            \n",
    "            for i in range(len(archive)):\n",
    "                \n",
    "                key = list(archive.keys())[i]  \n",
    "                self.keys[idx] = (a, key)\n",
    "                idx += 1\n",
    "                \n",
    "                for j in range(archive[key].shape[0]):\n",
    "                    \n",
    "                    self.d[idx2] = archive[key][j]\n",
    "                    idx2 +=1\n",
    "                    \n",
    "        self._archive=None\n",
    "    @property\n",
    "    def archives(self):\n",
    "        if self._archives is None: \n",
    "            self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.h5_paths]\n",
    "        return self._archives\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.d)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        data = self.d[index].astype(np.float32)\n",
    "        data = torch.from_numpy(data)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4401d-5c57-4a79-a8fd-46e704fe5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(H5Dataset(h5_files),batch_size=16,shuffle=True)\n",
    "loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8bd3-5adf-49c1-9e05-9469ee12f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "doenum = enumerate(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847771fc-ab4b-4d70-9534-7a334c946c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,data = next(doenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb90d9-be11-44d4-abb6-0b793c21887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd742d1-0308-4b07-9579-c6e8cda989dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4)\n",
    "nth = 0\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(data[nth],clim=(0,50),cmap='gray')\n",
    "        nth +=1\n",
    "        \n",
    "plt.subplots_adjust(wspace=0,hspace=0)\n",
    "fig.patch.set_facecolor('#423f3b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e97c0-147c-45e1-bc87-bdf86bbfcf6a",
   "metadata": {},
   "source": [
    "# Conv Calculater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba4bce-5cdc-4776-94c6-b6b60e57e5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_conv_dims(input_size,paddings:list,kernels:list,strides:list):\n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(input_size)\n",
    "    for i in range(len(paddings)):\n",
    "        \n",
    "        output_size = (input_size + (2*paddings[i]) - (kernels[i] - 1) - 1)/strides[i] + 1\n",
    "        outputs.append(int(output_size))\n",
    "        input_size = output_size\n",
    "        \n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa062b89-cf44-465e-81ff-d419520a8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_forward = [5,3,5,3]\n",
    "paddings_forward= [0,0,0,0]\n",
    "strides_forward = [2,1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09682b-aee6-48fa-969b-3d640d124f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_conv_dims(160,paddings_forward,kernels_forward,strides_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e2731-6f72-4550-ae54-a4ff0b64d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "34*34*32/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fb89a-2555-4eb2-b6a6-ca2d70003f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "160*160/2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b454f3c-15c1-4ca9-a994-b1d60e11cfbf",
   "metadata": {},
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b89e7-1f39-4d38-b7a8-21baefa9568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \n",
    "    def __init__(self,latent_dim=200):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential( \n",
    "            nn.Linear(25600,12800), # 154x154x20 --> 155x155x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(12800,6400), # 155x155x16 --> 312x312x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(6400,1024),# 312x312x16 --> 314x314x8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,512), # 314x314x8 --> 320x320x3\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,latent_dim),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.latent = nn.Linear(latent_dim,512)\n",
    "                \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(512,1024), # 154x154x20 --> 155x155x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,2048), # 155x155x16 --> 312x312x16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(2048,6400),# 312x312x16 --> 314x314x8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(6400,12800),# 314x314x8 --> 320x320x3\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(12800,25600),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        latent = self.latent(x)\n",
    "        \n",
    "        x = self.decoder(latent)\n",
    "    \n",
    "        return x,latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03595b66-0ef3-4449-bb42-a8be51522cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77001d96-c91b-44d2-80dc-fdc3033376d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e6c46-c052-43f1-9815-d6ae8bd32d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,device,EPOCH):\n",
    "    \n",
    "    #img_list = []\n",
    "    losses = []\n",
    "    iters = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    print(\"Starting Training Loop...\")\n",
    "    with tqdm(total=len(train_loader)*EPOCH) as tt:\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            \n",
    "            total_loss, batch_count = 0, 0\n",
    "            \n",
    "            for idx, batch in enumerate(train_loader):\n",
    "                \n",
    "                batch = batch.to(device)\n",
    "                \n",
    "                output, latent = model(batch)\n",
    "                \n",
    "                loss = criterion(output,batch.view(batch.size(0),-1))\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count +=1\n",
    "                tt.update()\n",
    "                losses.append(loss.item())\n",
    "                iters += 1\n",
    "                    \n",
    "                if iters % 100 == 0:    \n",
    "                    print('[%d/%d][%d/%d]\\t Loss: %.4f\\t'\n",
    "                      % (epoch, EPOCH, idx, len(train_loader),\n",
    "                         total_loss / batch_count))\n",
    "                    \n",
    "                    \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cf7f9-bad5-44f1-a382-6a9ecaa9c92d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(model=model,\n",
    "      train_loader=loader,\n",
    "      optimizer=optimizer,\n",
    "      device=device,\n",
    "      EPOCH=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fda3f-2c98-454d-86be-3a24638e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = torch.load('models/vae_250E_3e-6_128_model.pt')\n",
    "#model2 = torch.load('models/vae_220E_3e-6_64_model.pt')\n",
    "#model3 = torch.load('models/vae_500E_3e-6_64_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af55545-3a4f-4236-a5d3-46d54cb6a649",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1563143-93e9-4b79-80a8-60f1d15a9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model,data_loader):\n",
    "    \n",
    "    _,images   = next(enumerate(data_loader))\n",
    "    batch_size = images.size(0) \n",
    "    channel_size = 1\n",
    "    w_h = images.size(2)\n",
    "    \n",
    "    if next(model.encoder.parameters()).shape[1] != 3:\n",
    "        images_flatten = images.view(batch_size, -1)\n",
    "        output,_ = model(images_flatten.to(device))\n",
    "    else:\n",
    "        output,_ = model(images.to(device))\n",
    "    \n",
    "    images = images.numpy()\n",
    "    output = output.view(batch_size, channel_size, w_h, w_h)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    \n",
    "    _, axes = plt.subplots(nrows=2,ncols=8,figsize=(28,8))\n",
    "\n",
    "    for idx,(row,col) in enumerate(itertools.product(range(2),range(8))):\n",
    "            \n",
    "            axes[row][col].imshow(np.squeeze(output[idx]),clim=(0,50),cmap='gray')\n",
    "            axes[row][col].set_yticks([])\n",
    "            axes[row][col].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5999d-6d16-458f-8575-21b2de705428",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(model,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1181e7-8891-4d47-828e-072b8af4dfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34ece4-edbf-40bd-b565-45a86f8bfbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e3b3e-ed3b-491c-af5e-db7e718c3473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "876458b6-2dd6-49fd-88a7-d5db715f98a2",
   "metadata": {},
   "source": [
    "# Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeeedad-e347-4938-9823-e8b098e8f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_imgs_conv(model,nsample):\n",
    "    \n",
    "    rand_features = torch.randn(nsample, 500).to(device)\n",
    "    x = model.linear(rand_features)\n",
    "    x = x.view(12,20,154,154)\n",
    "    rand_generated = model.decoder(x)\n",
    "    \n",
    "    images = rand_generated.view(nsample,1,320,320)\n",
    "    images = images.cpu().detach().numpy()\n",
    "    \n",
    "    for i in range(12):\n",
    "            plt.subplot(3,4,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(np.transpose((images[i]*255).astype(np.uint8),(1, 2, 0)),cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c248f-04bb-46ca-9841-9e2f6f4027c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_random_imgs_conv(vae_model,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131ed73-312a-4da6-813c-dd173f2a8f8b",
   "metadata": {},
   "source": [
    "# Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad79585-0373-4dd7-bad5-6096091b2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize2d_interactive(data,targets,classes):\n",
    "    \n",
    "    hover_data = pd.DataFrame({'index':np.arange(len(data)),\n",
    "                               'label':targets})\n",
    "    \n",
    "    hover_data['item'] = hover_data.label.map(classes)\n",
    "    mapping = umap.UMAP().fit(data)\n",
    "    umap.plot.output_notebook()\n",
    "    p = umap.plot.interactive(mapping, labels=targets, hover_data=hover_data, point_size=2,)\n",
    "    umap.plot.show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad690bc-4c71-42bf-bcd5-f6edaa87d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize2d(data,targets):\n",
    "    \n",
    "    mapping = umap.UMAP().fit(data)\n",
    "    umap.plot.points(mapping, theme='fire');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e87359-0188-4749-8d9d-a52e537e5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(vae_model,'noisy_250.pt')\n",
    "vae_model = torch.load('noisy_250.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27210bf5-483c-4dc7-b96d-21bd7cb75631",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b5bf4-2a04-4a9b-b191-35fe9aac77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var = vae_model.mean(x), vae_model.log_var(x)\n",
    "encoded = vae_model.reparameterize(z_mean,z_log_var)\n",
    "visualize2d(encoded.cpu().detach().numpy(),targets='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e6415-d7ba-4b03-b623-fe2ea4a11031",
   "metadata": {},
   "source": [
    "# Regenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6214853-9f90-4584-a62b-e2225f8ecac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.File(h5_files[1],\"r\").keys()\n",
    "regenerate = np.array(h5py.File(h5_files[1],\"r\")['1386_HIP-68245_F300M_MASKA335R_sci'])[3:4]\n",
    "original = np.squeeze(regenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d6064-b824-4034-bd03-46c8cc0f5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = regenerate.astype(np.float32)\n",
    "data = torch.from_numpy(data)\n",
    "data = data.view(1,1,320,320).to(device)\n",
    "_,_,_,regenerated = vae_model(data)\n",
    "result = np.squeeze(regenerated.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02bceb-047f-43cb-ad52-3a93a0d1dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True, figsize=(25,10))\n",
    "\n",
    "for images, row in zip([result,original],axes):\n",
    "    \n",
    "    row.imshow(images,cmap='gray')\n",
    "    row.get_xaxis().set_visible(False)\n",
    "    row.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded5883-799a-48ce-a9d1-2d3bc624625e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
