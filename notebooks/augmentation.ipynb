{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from astropy.io import fits\n",
    "import umap\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injections = glob.glob('/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/injections/*.png')[:100]\n",
    "augmentations = glob.glob('/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/sci_imgs/*')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(imgs):\n",
    "\n",
    "\n",
    "    _, axes = plt.subplots(nrows=10,ncols=10,figsize=(20,20))\n",
    "\n",
    "    for i, (row,col) in enumerate(product(range(10),range(10))):\n",
    "\n",
    "\n",
    "        axes[row][col].imshow(imgs[i])\n",
    "    \n",
    "        axes[row][col].set_yticks([])\n",
    "        axes[row][col].set_xticks([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0,hspace=0)\n",
    "    plt.savefig(f'fig_augs.jpg',format='jpg',dpi=1000)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for i in augmentations:\n",
    "\n",
    "    img = PIL.Image.open(i).convert('L')\n",
    "    img = np.array(img)\n",
    "    imgs.append(img)\n",
    "\n",
    "imgs = np.concatenate(np.expand_dims(imgs, axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_RGB(hex_str):\n",
    "    \"\"\" #FFFFFF -> [255,255,255]\"\"\"\n",
    "    #Pass 16 to the integer function for change of base\n",
    "    return [int(hex_str[i:i+2], 16) for i in range(1,6,2)]\n",
    "\n",
    "def get_color_gradient(c1, c2, n):\n",
    "    \"\"\"\n",
    "    Given two hex colors, returns a color gradient\n",
    "    with n colors.\n",
    "    \"\"\"\n",
    "    assert n > 1\n",
    "    c1_rgb = np.array(hex_to_RGB(c1))/255\n",
    "    c2_rgb = np.array(hex_to_RGB(c2))/255\n",
    "    mix_pcts = [x/(n-1) for x in range(n)]\n",
    "    rgb_colors = [((1-mix)*c1_rgb + (mix*c2_rgb)) for mix in mix_pcts]\n",
    "    return [\"#\" + \"\".join([format(int(round(val*255)), \"02x\") for val in item]) for item in rgb_colors]\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca_comps(pca_comps):\n",
    "\n",
    "    color1 = \"#D4CC47\"\n",
    "    color2 = \"#7C4D8B\"\n",
    "    num_points = 200\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    plt.scatter(pca_comps[:,0],pca_comps[:,1],\n",
    "            color=get_color_gradient(color1, color2, num_points))\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Gradient Scatter\")\n",
    "    #plt.savefig(f'chair_{index}.png',format='png',dpi=100)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage3_products(suffix,directory):\n",
    "    return glob.glob(os.path.join(directory, f'*{suffix}.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Exonet(nn.Module):\n",
    "    \n",
    "    def __init__(self, convdim_enc_outputs:list, convdim_dec_outputs:list, kernels_enc:list, strides_enc:list, kernels_dec:list, strides_dec:list):\n",
    "        \n",
    "        super(Exonet,self).__init__()\n",
    "        \n",
    "        self.convdim_enc = convdim_enc_outputs\n",
    "        self.convdim_dec = convdim_dec_outputs\n",
    "        self.kernels_enc = kernels_enc\n",
    "        self.strides_enc = strides_enc\n",
    "        self.kernels_dec = kernels_dec\n",
    "        self.strides_dec = strides_dec\n",
    "        self.C       = 8 \n",
    "        \n",
    "        self.encoder  = nn.Sequential(\n",
    "                        \n",
    "            nn.Conv2d(in_channels=1, out_channels=self.C, stride=self.strides_enc[0], kernel_size=self.kernels_enc[0]), #1\n",
    "            nn.BatchNorm2d(self.C),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C, out_channels=self.C*2, stride=self.strides_enc[1], kernel_size=self.kernels_enc[1]), #2\n",
    "            nn.BatchNorm2d(self.C*2),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2, out_channels=self.C*2, stride=self.strides_enc[2], kernel_size=self.kernels_enc[2]), #3\n",
    "            nn.BatchNorm2d(self.C*2),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2, out_channels=self.C*2, stride=self.strides_enc[3], kernel_size=self.kernels_enc[3]), #4 \n",
    "            nn.BatchNorm2d(self.C*2),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*2, out_channels=self.C*4, stride=self.strides_enc[4], kernel_size=self.kernels_enc[4]), #5\n",
    "            nn.BatchNorm2d(self.C*4),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*4, out_channels=self.C*8, stride=self.strides_enc[5], kernel_size=self.kernels_enc[5]), #6\n",
    "            nn.BatchNorm2d(self.C*8),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=self.C*8, out_channels=self.C*16, stride=self.strides_enc[6], kernel_size=self.kernels_enc[6]), #7\n",
    "            nn.BatchNorm2d(self.C*16),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "        \n",
    "        ) \n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "        \n",
    "                nn.Linear((self.C*16)*convdim_outputs[-1]**2,4096),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(4096,2048),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(2048,1024),\n",
    "                nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.latent = nn.Linear(1024,1024)\n",
    "\n",
    "        self.fc2   = nn.Sequential(\n",
    "\n",
    "                nn.Linear(1024,2048),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(2048,4096),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(4096,(self.C*16)*convdim_outputs[-1]**2),\n",
    "                nn.SiLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "                        \n",
    "            nn.ConvTranspose2d(in_channels=self.C*16, out_channels=self.C*8, stride=self.strides_dec[0], kernel_size=self.kernels_dec[0]), #1\n",
    "            nn.BatchNorm2d(self.C*8),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C*8, out_channels=self.C*4, stride=self.strides_dec[1], kernel_size=self.kernels_dec[1]), #2\n",
    "            nn.BatchNorm2d(self.C*4),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C*4, out_channels=self.C*2, stride=self.strides_dec[2], kernel_size=self.kernels_dec[2]), #3\n",
    "            nn.BatchNorm2d(self.C*2),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C*2, stride=self.strides_dec[3], kernel_size=self.kernels_dec[3]), #4 \n",
    "            nn.BatchNorm2d(self.C*2),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C*2, out_channels=self.C, stride=self.strides_dec[4], kernel_size=self.kernels_dec[4]), #5\n",
    "            nn.BatchNorm2d(self.C),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C, out_channels=self.C, stride=self.strides_dec[5], kernel_size=self.kernels_dec[5]), #6\n",
    "            nn.BatchNorm2d(self.C),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=self.C, out_channels=1, stride=self.strides_dec[6], kernel_size=self.kernels_dec[6]), #7\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "        ) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        bs       = x.size(0)\n",
    "\n",
    "        x       = self.encoder(x)\n",
    "        x       = x.view(x.size(0),-1)\n",
    "\n",
    "        x       = self.fc1(x)\n",
    "        latents = self.latent(x)\n",
    "        x       = self.fc2(latents)\n",
    "\n",
    "        x       = x.view(bs,self.C*16,convdim_outputs[-1],convdim_outputs[-1])\n",
    "        x       = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =torch.load('/home/sarperyn/model_exp-2_epoch-140.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_paths):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.transform  = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self,):\n",
    "\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_path = self.image_paths[index]\n",
    "        image      = Image.open(image_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        if torch.isnan(image).any().item():\n",
    "            torch.nan_to_num(image)\n",
    "            \n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injections = glob.glob('/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/injections/*.png')[:100]\n",
    "augmentations = glob.glob('/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/sci_imgs/*')[:100]\n",
    "test = injections + augmentations\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata        = SynDataset(image_paths=test)\n",
    "syndata_loader = DataLoader(dataset=syndata, batch_size=200, shuffle=True)\n",
    "batch = next(iter(syndata_loader)).to('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x       = model.encoder(batch)\n",
    "x       = x.view(x.size(0),-1)\n",
    "x       = model.fc1(x)\n",
    "latents = model.latent(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_comps = umap.UMAP().fit(latents.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_comps(umap_comps.embedding_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_numpy(img_paths):\n",
    "    img_numpy = []\n",
    "    for img_dir in img_paths:\n",
    "        image   = PIL.Image.open(img_dir)\n",
    "        image   = np.expand_dims(np.array(image),axis=0)\n",
    "        img_numpy.append(image)\n",
    "    img_numpy = np.concatenate(img_numpy)\n",
    "\n",
    "    return img_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(files_dict,img_dirs):\n",
    "    \n",
    "    for file_name, dirs in files_dict.items():\n",
    "\n",
    "        for img_dir in img_dirs:\n",
    "            \n",
    "            f_name = '_'.join(img_dir.split('/')[-1].split('.')[0].split('_')[:5])\n",
    "\n",
    "            if file_name == f_name:\n",
    "\n",
    "                dirs.append(img_dir)\n",
    "\n",
    "    return files_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psf_dict(file_names):\n",
    "\n",
    "    files_dict = {}\n",
    "\n",
    "    for file in file_names:\n",
    "    \n",
    "        name = file.split('/')[-1].split('.')[0]\n",
    "        files_dict[name] = []\n",
    "\n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_dict(final_dict):\n",
    "\n",
    "    batch_dict = {}\n",
    "\n",
    "    for file_name, dirs in final_dict.items():\n",
    "\n",
    "        batch = create_batch_numpy(dirs)\n",
    "\n",
    "        batch_dict[file_name] = batch\n",
    "\n",
    "    return batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arrays_to_fits(psfstacks_nircam_1386, batch_dict):\n",
    "\n",
    "    for idx, fits_file in enumerate(psfstacks_nircam_1386):\n",
    "\n",
    "        with fits.open(fits_file, mode='update') as hdul:\n",
    "            \n",
    "            hdul[1].data = batch_dict[psfstacks_nircam_1386[idx].split('.')[0].split('/')[-1]]\n",
    "            hdul.flush()  # changes are written back to original.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = sorted(glob.glob('/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/sci_imgs/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_1386_nircam = f'/data/scratch/bariskurtkaya/dataset/NIRCAM/1386/mastDownload/JWST'\n",
    "psfstacks_nircam_1386 = get_stage3_products(suffix='psfstack',directory=directory_1386_nircam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = create_psf_dict(psfstacks_nircam_1386)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = get_dict(file_names, img_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict = get_batch_dict(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays_to_fits(psfstacks_nircam_1386, batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = fits.open(psfstacks_nircam_1386[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwst-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
